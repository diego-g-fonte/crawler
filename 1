import requests
from bs4 import BeautifulSoup

# Define the URL of the search results page
url = "https://tesiunam.dgb.unam.mx/F/4EYVMIQMGNH7IYSATJTIE6LIXKKYXQYVJRBI22FKIV3F28CPU8-02138?func=find-b&local_base=TES01&request=Licenciatura+en+Lengua+y+Literaturas+Modernas+Inglesas&find_code=WRD&adjacent=N&filter_code_2=WYR&filter_request_2=2006&filter_code_3=WYR&filter_request_3=2023"

# Make a GET request to the page and get the HTML content
response = requests.get(url)
html_content = response.content

# Parse the HTML content with BeautifulSoup
soup = BeautifulSoup(html_content, "html.parser")

# Find the results table on the page
table = soup.find("table", {"class": "stdlist"})

# Find all rows in the table (excluding the header row)
rows = table.find_all("tr")[1:]

# Extract the links from the sixth column of each row
links = []
for row in rows:
    cells = row.find_all("td")
    link = cells[5].find("a")["href"]
    links.append(link)

# Save the links to a text file
with open("links.txt", "w") as file:
    file.write("\n".join(links))
